<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-perception-systems" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Chapter 4: Perception Systems in Humanoids | Humanoid Robotics Book</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/docs/perception-systems"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="ur"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Chapter 4: Perception Systems in Humanoids | Humanoid Robotics Book"><meta data-rh="true" name="description" content="The Robot&#x27;s Window to the World"><meta data-rh="true" property="og:description" content="The Robot&#x27;s Window to the World"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/docs/perception-systems"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/perception-systems" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/ur/docs/perception-systems" hreflang="ur"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/perception-systems" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Chapter 4: Perception Systems in Humanoids","item":"https://your-docusaurus-site.example.com/docs/perception-systems"}]}</script><link rel="stylesheet" href="/assets/css/styles.7bf2df35.css">
<script src="/assets/js/runtime~main.24f6cb3b.js" defer="defer"></script>
<script src="/assets/js/main.830b497a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logosk1.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logosk1.png" alt="Humanoid Robotics Book Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logosk1.png" alt="Humanoid Robotics Book Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Humanoid Robotics Book</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Book</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro"><span title="Welcome to Humanoid Robotics Book" class="linkLabel_WmDU">Welcome to Humanoid Robotics Book</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/introduction-to-physical-ai"><span title="Chapter 1: Introduction to Physical AI" class="linkLabel_WmDU">Chapter 1: Introduction to Physical AI</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/foundations-of-robotics"><span title="Chapter 2: Foundations of Robotics: Systems, Structure &amp; Core Mechanisms" class="linkLabel_WmDU">Chapter 2: Foundations of Robotics: Systems, Structure &amp; Core Mechanisms</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/human-inspired-design-principles"><span title="Chapter 3: Human-Inspired Design Principles in Humanoid Robotics" class="linkLabel_WmDU">Chapter 3: Human-Inspired Design Principles in Humanoid Robotics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/docs/perception-systems"><span title="Chapter 4: Perception Systems in Humanoids" class="linkLabel_WmDU">Chapter 4: Perception Systems in Humanoids</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/ai-deep-learning-and-control"><span title="Chapter 5: AI, Deep Learning &amp; Control Systems" class="linkLabel_WmDU">Chapter 5: AI, Deep Learning &amp; Control Systems</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/locomotion-and-manipulation"><span title="Chapter 6: Humanoid Locomotion and Manipulation" class="linkLabel_WmDU">Chapter 6: Humanoid Locomotion and Manipulation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/urdu-translation"><span title="اردو ترجمہ" class="linkLabel_WmDU">اردو ترجمہ</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Chapter 4: Perception Systems in Humanoids</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Chapter 4: Perception Systems in Humanoids</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-robots-window-to-the-world">The Robot&#x27;s Window to the World<a href="#the-robots-window-to-the-world" class="hash-link" aria-label="Direct link to The Robot&#x27;s Window to the World" title="Direct link to The Robot&#x27;s Window to the World" translate="no">​</a></h2>
<p>A robot, no matter how perfectly constructed, is merely an inert machine without the ability to perceive the world around it. Perception is the fundamental process of gathering information from the environment and interpreting it to build an internal understanding, or &quot;world model.&quot; This model is the foundation upon which all intelligent action is built. For a humanoid robot designed to navigate the complexity and uncertainty of human environments, a sophisticated perception system is not just a feature—it is the very essence of its autonomy.</p>
<p>This chapter explores the array of sensors that act as a humanoid&#x27;s eyes, ears, and nerves. We will delve into how these sensors work, what kind of data they provide, and how the robot&#x27;s AI fuses this information to create a coherent and actionable picture of reality. Drawing heavy inspiration from human senses, these systems are a testament to the principles of bio-inspired design, enabling robots to see, hear, and &quot;feel&quot; their way through the world. We will cover the two main categories of perception: <em>exteroception</em> (sensing the external world) and <em>proprioception</em> (sensing the robot&#x27;s own internal state).</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="exteroception-sensing-the-external-world">Exteroception: Sensing the External World<a href="#exteroception-sensing-the-external-world" class="hash-link" aria-label="Direct link to Exteroception: Sensing the External World" title="Direct link to Exteroception: Sensing the External World" translate="no">​</a></h2>
<p>Exteroception is how a robot gathers data about its surroundings. The goal is to answer critical questions like: &quot;What is around me?&quot;, &quot;Where are the obstacles?&quot;, and &quot;Who is interacting with me?&quot;.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="vision-the-primary-sense">Vision: The Primary Sense<a href="#vision-the-primary-sense" class="hash-link" aria-label="Direct link to Vision: The Primary Sense" title="Direct link to Vision: The Primary Sense" translate="no">​</a></h3>
<p>For humans and humanoids alike, vision is the richest and most critical sensory modality. It provides a vast amount of information about object identity, location, texture, and color from a safe distance.</p>
<ul>
<li class="">
<p><strong>Cameras:</strong> The robotic equivalent of the human eye. Most humanoids use at least a pair of cameras to achieve <strong>stereo vision</strong>. Just as our two eyes give us depth perception, a stereo camera system allows the robot to compare the images from two slightly different viewpoints to calculate the distance to objects in the scene. This is crucial for navigation (avoiding collisions) and manipulation (accurately reaching for an object).</p>
</li>
<li class="">
<p><strong>LiDAR (Light Detection and Ranging):</strong> While cameras provide rich color and texture, they can be fooled by lighting conditions. LiDAR complements vision by providing extremely precise 3D structural information. It works by sending out pulses of laser light and measuring the time it takes for the light to bounce back. This process, repeated millions of times per second, generates a dense &quot;point cloud&quot;—a detailed 3D map of the environment. This is invaluable for robustly mapping a room, detecting obstacles, and understanding the geometry of the robot&#x27;s workspace, regardless of whether the lights are on or off.</p>
</li>
<li class="">
<p><strong>Depth Sensors:</strong> These sensors, like the structured light or time-of-flight cameras found in many consumer devices, offer a compromise between cameras and LiDAR. They project a pattern of infrared light into the scene and measure its distortion to calculate depth, providing a real-time depth image that is less computationally intensive to process than raw stereo vision.</p>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="auditory-sensing-hearing-and-understanding">Auditory Sensing: Hearing and Understanding<a href="#auditory-sensing-hearing-and-understanding" class="hash-link" aria-label="Direct link to Auditory Sensing: Hearing and Understanding" title="Direct link to Auditory Sensing: Hearing and Understanding" translate="no">​</a></h3>
<p>Sound provides vital information that vision cannot, such as events happening outside the robot&#x27;s line of sight.</p>
<ul>
<li class=""><strong>Microphone Arrays:</strong> Humanoid robots are typically equipped with multiple microphones. By analyzing the minute differences in the time and volume at which a sound arrives at each microphone, the robot can determine the direction of the sound source. This allows it to turn and face a person who is speaking, react to a warning shout, or investigate an unusual noise. The primary application is, of course, speech recognition, allowing for natural language interaction with human users.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="tactile-sensing-the-sense-of-touch">Tactile Sensing: The Sense of Touch<a href="#tactile-sensing-the-sense-of-touch" class="hash-link" aria-label="Direct link to Tactile Sensing: The Sense of Touch" title="Direct link to Tactile Sensing: The Sense of Touch" translate="no">​</a></h3>
<p>Vision can tell a robot where an object is, but touch tells it what that object feels like and how to interact with it. For a robot designed to manipulate objects or interact safely with people, tactile sensing is indispensable.</p>
<ul>
<li class="">
<p><strong>Force-Torque Sensors:</strong> Placed in the robot&#x27;s wrists, ankles, and waist, these sensors measure the forces and torques being exerted on the robot&#x27;s limbs. They are critical for balance—if the robot starts to tip, these sensors will feel the change in forces and allow the AI to adjust its posture. They also enable compliant motion, allowing the robot to yield gently when it comes into contact with a person or an unexpected object.</p>
</li>
<li class="">
<p><strong>&quot;Electronic Skin&quot;:</strong> To replicate the sensitivity of human skin, researchers are developing flexible sheets of tactile sensors that can be wrapped around a robot&#x27;s fingers, hands, and body. These sensors can detect pressure, vibration, and texture. This allows a robot to know if its grip on an object is slipping, to identify an object by feel alone, and to ensure that any physical interaction with a human is gentle and safe.</p>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="proprioception-sensing-the-self">Proprioception: Sensing the Self<a href="#proprioception-sensing-the-self" class="hash-link" aria-label="Direct link to Proprioception: Sensing the Self" title="Direct link to Proprioception: Sensing the Self" translate="no">​</a></h2>
<p>Proprioception is the robot&#x27;s sense of its own body. It answers the question: &quot;What is my body doing?&quot;. Without it, coordinated movement would be impossible.</p>
<ul>
<li class="">
<p><strong>Encoders:</strong> These are the most fundamental proprioceptive sensors, found in almost every robotic joint. An encoder is a sensor that measures the precise angle or position of a motor. By reading the encoders in all its joints, the robot&#x27;s AI knows the exact configuration of its limbs at all times. This information is the foundation of kinematic calculations—knowing the joint angles allows the robot to compute the position of its hand or foot.</p>
</li>
<li class="">
<p><strong>Inertial Measurement Units (IMU):</strong> An IMU is the robotic equivalent of the human inner ear&#x27;s vestibular system, which provides our sense of balance. An IMU typically contains a 3-axis accelerometer and a 3-axis gyroscope.</p>
<ul>
<li class=""><strong>Accelerometers</strong> measure linear acceleration, telling the robot how it is moving and providing a sense of gravity&#x27;s direction.</li>
<li class=""><strong>Gyroscopes</strong> measure angular velocity, telling the robot how fast it is rotating or tilting.
By combining data from these sensors, the IMU provides a continuous estimate of the robot&#x27;s orientation (roll, pitch, and yaw), which is absolutely essential for maintaining balance while walking or standing.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="sensor-fusion-creating-a-coherent-whole">Sensor Fusion: Creating a Coherent Whole<a href="#sensor-fusion-creating-a-coherent-whole" class="hash-link" aria-label="Direct link to Sensor Fusion: Creating a Coherent Whole" title="Direct link to Sensor Fusion: Creating a Coherent Whole" translate="no">​</a></h2>
<p>A humanoid robot is bombarded with a constant stream of data from this diverse array of sensors. The true magic of perception lies in <strong>sensor fusion</strong>—the process of combining all this partial, and sometimes conflicting, information into a single, unified model of the world and the robot&#x27;s place in it. The AI might fuse the 3D structure from LiDAR with the color information from a camera to confidently identify a &quot;red chair.&quot; It combines the IMU&#x27;s data on torso tilt with the force sensor readings from the feet to make a robust decision about how to adjust its posture to stay balanced. This holistic understanding, created by intelligently integrating all sensory input, is what allows a humanoid robot to move beyond simple programmed actions and begin to perceive, understand, and react to the world with a semblance of true awareness.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/human-inspired-design-principles"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Chapter 3: Human-Inspired Design Principles in Humanoid Robotics</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/ai-deep-learning-and-control"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Chapter 5: AI, Deep Learning &amp; Control Systems</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#the-robots-window-to-the-world" class="table-of-contents__link toc-highlight">The Robot&#39;s Window to the World</a></li><li><a href="#exteroception-sensing-the-external-world" class="table-of-contents__link toc-highlight">Exteroception: Sensing the External World</a><ul><li><a href="#vision-the-primary-sense" class="table-of-contents__link toc-highlight">Vision: The Primary Sense</a></li><li><a href="#auditory-sensing-hearing-and-understanding" class="table-of-contents__link toc-highlight">Auditory Sensing: Hearing and Understanding</a></li><li><a href="#tactile-sensing-the-sense-of-touch" class="table-of-contents__link toc-highlight">Tactile Sensing: The Sense of Touch</a></li></ul></li><li><a href="#proprioception-sensing-the-self" class="table-of-contents__link toc-highlight">Proprioception: Sensing the Self</a></li><li><a href="#sensor-fusion-creating-a-coherent-whole" class="table-of-contents__link toc-highlight">Sensor Fusion: Creating a Coherent Whole</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title"></div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://facebook.com/your-profile" target="_blank" rel="noopener noreferrer" class="footer__link-item social-icon facebook">Facebook<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://instagram.com/your-profile" target="_blank" rel="noopener noreferrer" class="footer__link-item social-icon instagram">Instagram<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title"></div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://linkedin.com/in/your-profile" target="_blank" rel="noopener noreferrer" class="footer__link-item social-icon linkedin">LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://twitter.com/your-profile" target="_blank" rel="noopener noreferrer" class="footer__link-item social-icon x">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Humanoid Robotics Book. Built By Saeed Khan with Docusaurus.</div></div></div></footer></div>
</body>
</html>